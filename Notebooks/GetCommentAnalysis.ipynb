{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMMENTS ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running this file allows to get the complete analysis of comments data from a given city's Airbnbs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "import nltk\n",
    "import matplotlib as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from langdetect import detect\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "sid = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(comment):\n",
    "    '''\n",
    "    takes a comment as an argument, sent_tokenize() it to seperate the sentences\n",
    "    then computes the scores of negativity, neutrality, positivity and compound for each sentence\n",
    "    and finally compute the mean of these scores for the whole comment\n",
    "    \n",
    "    '''\n",
    "    # tokenize comment to get seperated sentences\n",
    "    comment_tk = nltk.sent_tokenize(comment)\n",
    "    \n",
    "    # compute sentiment scores for each sentence\n",
    "    scores = list()\n",
    "    for c in comment_tk:\n",
    "        scores.append(sid.polarity_scores(c))\n",
    "    \n",
    "    # compute mean scores for the comment\n",
    "    neg = 0\n",
    "    neu = 0\n",
    "    pos = 0\n",
    "    comp = 0\n",
    "    for i in range(len(comment_tk)):\n",
    "        neg += scores[i]['neg']\n",
    "        neu += scores[i]['neu']\n",
    "        pos += scores[i]['pos']\n",
    "        comp += scores[i]['compound']\n",
    "    \n",
    "    mean_neg = neg/len(comment_tk)\n",
    "    mean_neu = neu/len(comment_tk)\n",
    "    mean_pos = pos/len(comment_tk)\n",
    "    mean_comp = comp/len(comment_tk)\n",
    "    \n",
    "    return [mean_neg, mean_neu, mean_pos, mean_comp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_comments(comments):\n",
    "    print('This data contains', comments.shape[0], 'lines.')\n",
    "    \n",
    "    # remove NaN\n",
    "    comments = comments.dropna(how='any',axis=0)\n",
    "    \n",
    "    # remove comments only filled with whitespaces\n",
    "    comments['isSpace'] = comments['comments'].apply(lambda x: x.isspace())\n",
    "    comments = comments[comments.isSpace == False]\n",
    "    comments = comments.drop(columns=['isSpace'])\n",
    "    \n",
    "    # remove all non-alphabetical characters to allow detect() to work\n",
    "    regex = re.compile('[^A-Za-zÀ-ÿ]')      \n",
    "    comments['rm_comments'] = comments['comments'].apply(lambda x: regex.sub(' ', x))\n",
    "    \n",
    "    # again, remove comments only filled with whitespaces\n",
    "    comments['isSpace'] = comments['rm_comments'].apply(lambda x: x.isspace())\n",
    "    comments = comments[comments.isSpace == False]\n",
    "    comments = comments.drop(columns=['isSpace'])\n",
    "    \n",
    "    # detect the language of each comment\n",
    "    comments['language'] = comments['rm_comments'].apply(lambda x: detect(x))\n",
    "    \n",
    "    # as the previous step takes some time, the result is saved and can be loaded for further use\n",
    "    comments.to_pickle(\"./comments_languages.pkl\")\n",
    "    \n",
    "    # keep only english comments\n",
    "    comments_en = comments[comments.language == 'en']\n",
    "    \n",
    "    # non-alphabetical characters are removed but the ponctuation in the comments is kept\n",
    "    regex2 = re.compile('[^A-Za-zÀ-ÿ?!.,:;]')     \n",
    "    comments_en['ap_comments'] = comments_en['comments'].apply(lambda x: regex2.sub(' ', x))\n",
    "    \n",
    "    # remove unnecessary columns of next steps\n",
    "    comments_en = comments_en.drop(columns=['comments', 'rm_comments', 'language'])\n",
    "    \n",
    "    # get sentiment\n",
    "    comments_en['sentiment'] = comments_en['ap_comments'].apply(lambda x: get_sentiment(x))\n",
    "    \n",
    "    # get a column for each different score (neg, pos, neu, comp) of each comment\n",
    "    comments_en[['negativity','neutrality', 'positivity', 'compound']] = pd.DataFrame(comments_en.sentiment.values.tolist(), index = comments_en.index)\n",
    "\n",
    "    # remove unnecessary column\n",
    "    comments_en = comments_en.drop(columns=['sentiment'])\n",
    "    \n",
    "    # work on a copy as we remove columns that could be useful afterwards\n",
    "    comments_en_copy = comments_en.copy()\n",
    "    comments_en_copy = comments_en_copy.drop(columns=['id', 'date', 'reviewer_id', 'reviewer_name', 'ap_comments'])\n",
    "    \n",
    "    # compute the mean of each score (neg, pos, neu, comp) for a given housing (-> using listing_id to groupby)\n",
    "    comments_en_copy = comments_en_copy.groupby('listing_id').mean()\n",
    "    print('There are', comments_en_copy.shape[0], 'different housings in this city.')\n",
    "    \n",
    "    # plot \n",
    "    comments_en_copy.hist(bins=100)\n",
    "    \n",
    "    return comments, comments_en, comments_en_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading datas\n",
    "comments = pd.read_csv('./data/2019-09-14_Amsterdam_reviews.csv', header=0) # put the path to the file you want to analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments, comments_en, comments_en_copy = analyze_comments(comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_en.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_en_copy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
